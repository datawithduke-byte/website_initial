---
title: "AI is a tech wonder for the ages; but..."
date: 2025-10-05
summary: "What does a recent MIT study mean for the use of AI in industry and education settings across the world? Is there a link between AI usage and learning?"
slug: "ai_and_learning"
exclusive: true
external: true
---
## ...is AI killing brains?

So I've touched on it a little recently but aside from data, data literacy, statistics and technology, I'm also deeply interested in AI. Specifically the recent(ish) surge on popularity of LLMs and similar tools.

I've been pretty transparent in that I use a variety of AI tools to put this entire show together; from lesson planning, creating transcripts of recordings, creating images, telling bad jokes and helping with putting together the website.

I've learned a TON from different tools, particularly about how to construct a site, how different HTML tags work, how styling worksâ€¦ stuff I won't bore you with.

As you can probably tell, I've always been a fan of having AI be my sounding board and my expert partner, but not to do the work for me.

I've also mentioned, and maintain a promise that I write all of these blogs and speak the words on the videos with good old fashioned human input. Because, I'm not about making a quick buck with the latest fad. There are certain things that can and always should be driven by people, not computerised models.

So, given that's been my approach to AI for the last few years since GPT3 came out, I was surprised to read some info from a recent MIT study that, despite the drawbacks of the study itself, speaks quite conclusively about the negative effects of relying on AI models too much, specifically for research and learning.

I've not read the whole thing, just scanned through and read the interesting sections.

The study measured the impacts on connectivities in the brains of participants who undertook report writing tasks, some using mostly AI, some using it a little, others not using it at all (this is a simplistic explanation, you can [read the paper here](https://arxiv.org/pdf/2506.08872v1), or Time Magazine's article [about it here](https://time.com/7295195/ai-chatgpt-google-learning-school/) ).

There's still much work to be done, but the general thinking is that relying too much on AI can actually have a negative impact on learning patterns. Whether this applies to a broader set of cognitive tasks and cognition in general, I guess time will tell. 

But I can't help but wonder that if we get to a stage where the science says definitively that certain uses of AI basically makes us dumber, do you think people will change the way they use it? 

It's almost inconceivable at this point that people who use AI regularly will find changing habits trivial. And let's face it, if AI IS clogging up those neural pathways then will it be too late by the time we (a) know for certain and (b) have a strategy in place to combat the effects?

Either way, I think I'm going to continue to stick to my blend of questioning, learning and assessing when it comes to AI use. Knowing how I learn best means I can program it to work with me, not for me. 

And if you want to do the same? Well first, understanding how you learn is probably the first step. What do you think? Will you change the frequency or how you will use AI based on this study?